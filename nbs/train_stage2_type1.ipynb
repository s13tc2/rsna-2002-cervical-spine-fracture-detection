{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B58G4nXOXxk2"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCrRotdZX_tZ",
        "outputId": "6bc8cc7e-e251-4f6c-c6d6-f73b984e2c28"
      },
      "outputs": [],
      "source": [
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-`lsb_release -c -s` main\" | sudo tee /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "!apt-get -y -q update\n",
        "!apt-get -y -q install gcsfuse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MQvsY58YDe1",
        "outputId": "5345c124-a16f-429e-a973-6f024048ac13"
      },
      "outputs": [],
      "source": [
        "# mount comp data\n",
        "!mkdir -p tmp\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"ADD_GCS_PATH\" tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqT_4KGfYJMX",
        "outputId": "bea3c6c0-403b-4241-f2fd-c1065917c47f"
      },
      "outputs": [],
      "source": [
        "# mount preprocessed data\n",
        "!mkdir -p 'rsna-cropped-2d-224-0920-2m'\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"ADD_GCS_PATH\" 'rsna-cropped-2d-224-0920-2m'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTVQs31ZYpuO"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle && mv kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGFZK7s_YxHL",
        "outputId": "2b00059a-a3f1-4164-a811-13eeb56a9284"
      },
      "outputs": [],
      "source": [
        "### Extra files\n",
        "! kaggle datasets download -d boliu0/covn3d-same\n",
        "! kaggle datasets download -d haqishen/pylibjpeg140py3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeRn4DsrYyOO",
        "outputId": "72706375-3cce-4ef5-cc57-8a432ad40acb"
      },
      "outputs": [],
      "source": [
        "!unzip covn3d-same.zip && unzip pylibjpeg140py3.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHu4vmqoYzPP",
        "outputId": "49c77a30-2361-49a0-8e6c-82126deef715"
      },
      "outputs": [],
      "source": [
        "!pip -q install monai\n",
        "!pip -q install segmentation-models-pytorch==0.2.1\n",
        "!pip -q install pylibjpeg-1.4.0-py3-none-any.whl\n",
        "!pip -q install python_gdcm-3.0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
        "!pip -q install pydicom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tm8xOSt0Y02U"
      },
      "outputs": [],
      "source": [
        "!pip -q install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aImXNHKzY81A"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import gc\n",
        "import ast\n",
        "import cv2\n",
        "import time\n",
        "import timm\n",
        "import pickle\n",
        "import random\n",
        "import argparse\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import albumentations\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.cuda.amp as amp\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "%matplotlib inline\n",
        "rcParams['figure.figsize'] = 20, 8\n",
        "device = torch.device('cuda')\n",
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RgWCMgzY9Sc"
      },
      "outputs": [],
      "source": [
        "DEBUG = False\n",
        "\n",
        "kernel_type = '0920_1bonev2_effv2s_224_15_6ch_augv2_mixupp5_drl3_rov1p2_bs8_lr23e5_eta23e6_50ep'\n",
        "load_kernel = None\n",
        "load_last = True\n",
        "\n",
        "n_folds = 5\n",
        "backbone = 'tf_efficientnetv2_s_in21ft1k'\n",
        "\n",
        "image_size = 224\n",
        "n_slice_per_c = 15\n",
        "in_chans = 6\n",
        "\n",
        "init_lr = 23e-5\n",
        "eta_min = 23e-6\n",
        "batch_size = 8\n",
        "drop_rate = 0.\n",
        "drop_rate_last = 0.3\n",
        "drop_path_rate = 0.\n",
        "p_mixup = 0.5\n",
        "p_rand_order_v1 = 0.2\n",
        "\n",
        "data_dir = './rsna-cropped-2d-224-0920-2m/cropped_2d_224_15_ext0_5ch_0920_2m/cropped_2d_224_15_ext0_5ch_0920_2m'\n",
        "use_amp = True\n",
        "num_workers = 4\n",
        "out_dim = 1\n",
        "\n",
        "n_epochs = 75\n",
        "\n",
        "log_dir = './logs'\n",
        "model_dir = './models'\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlfjOoUiZFkY",
        "outputId": "4cef047a-89ed-489d-c309-dee22a778c34"
      },
      "outputs": [],
      "source": [
        "transforms_train = albumentations.Compose([\n",
        "    albumentations.Resize(image_size, image_size),\n",
        "    albumentations.HorizontalFlip(p=0.5),\n",
        "    albumentations.VerticalFlip(p=0.5),\n",
        "    albumentations.Transpose(p=0.5),\n",
        "    albumentations.RandomBrightness(limit=0.1, p=0.7),\n",
        "    albumentations.ShiftScaleRotate(shift_limit=0.3, scale_limit=0.3, rotate_limit=45, border_mode=4, p=0.7),\n",
        "\n",
        "    albumentations.OneOf([\n",
        "        albumentations.MotionBlur(blur_limit=3),\n",
        "        albumentations.MedianBlur(blur_limit=3),\n",
        "        albumentations.GaussianBlur(blur_limit=3),\n",
        "        albumentations.GaussNoise(var_limit=(3.0, 9.0)),\n",
        "    ], p=0.5),\n",
        "    albumentations.OneOf([\n",
        "        albumentations.OpticalDistortion(distort_limit=1.),\n",
        "        albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n",
        "    ], p=0.5),\n",
        "\n",
        "    albumentations.Cutout(max_h_size=int(image_size * 0.5), max_w_size=int(image_size * 0.5), num_holes=1, p=0.5),\n",
        "])\n",
        "\n",
        "transforms_valid = albumentations.Compose([\n",
        "    albumentations.Resize(image_size, image_size),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zhqeljWXZHbt",
        "outputId": "9a4a331f-7c28-489c-8fac-1f8aab2a8471"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('./train_seg.csv')\n",
        "\n",
        "sid = []\n",
        "cs = []\n",
        "label = []\n",
        "fold = []\n",
        "for _, row in df.iterrows():\n",
        "    for i in [1,2,3,4,5,6,7]:\n",
        "        sid.append(row.StudyInstanceUID)\n",
        "        cs.append(i)\n",
        "        label.append(row[f'C{i}'])\n",
        "        fold.append(row.fold)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'StudyInstanceUID': sid,\n",
        "    'c': cs,\n",
        "    'label': label,\n",
        "    'fold': fold\n",
        "})\n",
        "\n",
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfGulf9aZLkj"
      },
      "outputs": [],
      "source": [
        "class CLSDataset(Dataset):\n",
        "    def __init__(self, df, mode, transform):\n",
        "\n",
        "        self.df = df.reset_index()\n",
        "        self.mode = mode\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.df.iloc[index]\n",
        "        cid = row.c\n",
        "        \n",
        "        images = []\n",
        "        \n",
        "        for ind in list(range(n_slice_per_c)):\n",
        "            filepath = os.path.join(data_dir, f'{row.StudyInstanceUID}_{cid}_{ind}.npy')\n",
        "            image = np.load(filepath)\n",
        "            image = self.transform(image=image)['image']\n",
        "            image = image.transpose(2, 0, 1).astype(np.float32) / 255.\n",
        "            images.append(image)\n",
        "        images = np.stack(images, 0)\n",
        "\n",
        "        if self.mode != 'test':\n",
        "            images = torch.tensor(images).float()\n",
        "            labels = torch.tensor([row.label] * n_slice_per_c).float()\n",
        "            \n",
        "            if self.mode == 'train' and random.random() < p_rand_order_v1:\n",
        "                indices = torch.randperm(images.size(0))\n",
        "                images = images[indices]\n",
        "\n",
        "            return images, labels\n",
        "        else:\n",
        "            return torch.tensor(images).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKkona_NaE4x"
      },
      "outputs": [],
      "source": [
        "rcParams['figure.figsize'] = 20,8\n",
        "\n",
        "df_show = df\n",
        "dataset_show = CLSDataset(df_show, 'train', transform=transforms_train)\n",
        "loader_show = torch.utils.data.DataLoader(dataset_show, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "vVq-BQZPaH3F",
        "outputId": "7aead0b8-568f-4dd6-9909-93e182b6c7f0"
      },
      "outputs": [],
      "source": [
        "f, axarr = plt.subplots(2,4)\n",
        "for p in range(4):\n",
        "    idx = p * 20\n",
        "    imgs, lbl = dataset_show[idx]\n",
        "    axarr[0, p].imshow(imgs[7][:3].permute(1, 2, 0))\n",
        "    axarr[1, p].imshow(imgs[7][-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpDSZhHvaXSl"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CkamM10aa73",
        "outputId": "2de7cf92-fff8-4d43-9c97-2e6f5bc9d377"
      },
      "outputs": [],
      "source": [
        "encoder = timm.create_model(\n",
        "    'tf_efficientnetv2_s_in21ft1k',\n",
        "    in_chans=in_chans,\n",
        "    num_classes=out_dim,\n",
        "    features_only=False,\n",
        "    drop_rate=drop_rate,\n",
        "    drop_path_rate=drop_path_rate,\n",
        "    pretrained=False\n",
        ")\n",
        "print(encoder.conv_head)\n",
        "print(encoder.conv_head.out_channels)\n",
        "hdim = encoder.conv_head.out_channels\n",
        "print(encoder.classifier)\n",
        "encoder.classifier = nn.Identity()\n",
        "print(encoder.classifier)\n",
        "lstm = nn.LSTM(hdim, 256, num_layers=2, dropout=drop_rate, bidirectional=True, batch_first=True)\n",
        "print(lstm)\n",
        "head = nn.Sequential(\n",
        "    nn.Linear(512, 256),\n",
        "    nn.BatchNorm1d(256),\n",
        "    nn.Dropout(drop_rate_last),\n",
        "    nn.LeakyReLU(0.1),\n",
        "    nn.Linear(256, out_dim),\n",
        ")\n",
        "print(head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDPSYBoPaOLE"
      },
      "outputs": [],
      "source": [
        "class TimmModel(nn.Module):\n",
        "    def __init__(self, backbone, pretrained=False):\n",
        "        super(TimmModel, self).__init__()\n",
        "\n",
        "        self.encoder = timm.create_model(\n",
        "            backbone,\n",
        "            in_chans=in_chans,\n",
        "            num_classes=out_dim,\n",
        "            features_only=False,\n",
        "            drop_rate=drop_rate,\n",
        "            drop_path_rate=drop_path_rate,\n",
        "            pretrained=pretrained\n",
        "        )\n",
        "\n",
        "        if 'efficient' in backbone:\n",
        "            hdim = self.encoder.conv_head.out_channels\n",
        "            self.encoder.classifier = nn.Identity()\n",
        "        elif 'convnext' in backbone:\n",
        "            hdim = self.encoder.head.fc.in_features\n",
        "            self.encoder.head.fc = nn.Identity()\n",
        "\n",
        "\n",
        "        self.lstm = nn.LSTM(hdim, 256, num_layers=2, dropout=drop_rate, bidirectional=True, batch_first=True)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Dropout(drop_rate_last),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Linear(256, out_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):  # (bs, nslice, ch, sz, sz)\n",
        "        bs = x.shape[0]\n",
        "        x = x.view(bs * n_slice_per_c, in_chans, image_size, image_size)\n",
        "        feat = self.encoder(x)\n",
        "        feat = feat.view(bs, n_slice_per_c, -1)\n",
        "        feat, _ = self.lstm(feat)\n",
        "        feat = feat.contiguous().view(bs * n_slice_per_c, -1)\n",
        "        feat = self.head(feat)\n",
        "        feat = feat.view(bs, n_slice_per_c).contiguous()\n",
        "\n",
        "        return feat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-TToHYmbvqQ",
        "outputId": "f5f614b4-c3af-444b-ed17-311c2c58efea"
      },
      "outputs": [],
      "source": [
        "print(torch.rand(2, n_slice_per_c, in_chans, image_size, image_size).shape)\n",
        "x = torch.rand(2, n_slice_per_c, in_chans, image_size, image_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YsMdV1LbnUE",
        "outputId": "84d009c4-c058-4a1f-901f-ea0193f13efe"
      },
      "outputs": [],
      "source": [
        "m = TimmModel(backbone)\n",
        "m(torch.rand(2, n_slice_per_c, in_chans, image_size, image_size)).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hifDsTwZbtzo",
        "outputId": "f4caa8f1-d04e-4aa4-f1ee-5df5d84e4147"
      },
      "outputs": [],
      "source": [
        "x = torch.rand(2, n_slice_per_c, in_chans, image_size, image_size)\n",
        "bs = x.shape[0]\n",
        "print(bs)\n",
        "print(bs*n_slice_per_c, in_chans, image_size, image_size)\n",
        "x = x.view(bs * n_slice_per_c, in_chans, image_size, image_size)\n",
        "print(x.shape)\n",
        "feat = encoder(x)\n",
        "print(feat.shape)\n",
        "feat = feat.view(bs, n_slice_per_c, -1)\n",
        "print(feat.shape)\n",
        "lstm = nn.LSTM(hdim, 256, num_layers=2, dropout=drop_rate, bidirectional=True, batch_first=True)\n",
        "feat, _ = lstm(feat)\n",
        "print(feat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpChdGhib3_Y",
        "outputId": "a1498a1e-3561-46cc-dce0-bfa765ac0291"
      },
      "outputs": [],
      "source": [
        "feat = feat.contiguous().view(bs * n_slice_per_c, -1)\n",
        "print(feat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78uyeeXrcUwj",
        "outputId": "6ddb66d3-940a-4e06-9e87-6a88151eba84"
      },
      "outputs": [],
      "source": [
        "feat = head(feat)\n",
        "print(feat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNj3C_rlece0",
        "outputId": "0f72806a-d1ea-44a5-e5c2-512d7869b5c6"
      },
      "outputs": [],
      "source": [
        "feat = feat.view(bs, n_slice_per_c).contiguous()\n",
        "print(feat.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MTyDNPWenNE"
      },
      "source": [
        "# Loss & Metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EE9GM-2ree1u"
      },
      "outputs": [],
      "source": [
        "bce = nn.BCEWithLogitsLoss(reduction='none')\n",
        "\n",
        "\n",
        "def criterion(logits, targets, activated=False):\n",
        "    if activated:\n",
        "        losses = nn.BCELoss(reduction='none')(logits.view(-1), targets.view(-1))\n",
        "    else:\n",
        "        losses = bce(logits.view(-1), targets.view(-1))\n",
        "    losses[targets.view(-1) > 0] *= 2.\n",
        "    norm = torch.ones(logits.view(-1).shape[0]).to(device)\n",
        "    norm[targets.view(-1) > 0] *= 2\n",
        "    return losses.sum() / norm.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyf_ggEVesds"
      },
      "source": [
        "# Train & Valid func"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQK5Q7K3eqH_"
      },
      "outputs": [],
      "source": [
        "def mixup(input, truth, clip=[0, 1]):\n",
        "    indices = torch.randperm(input.size(0))\n",
        "    shuffled_input = input[indices]\n",
        "    shuffled_labels = truth[indices]\n",
        "\n",
        "    lam = np.random.uniform(clip[0], clip[1])\n",
        "    input = input * lam + shuffled_input * (1 - lam)\n",
        "    return input, truth, shuffled_labels, lam\n",
        "\n",
        "\n",
        "def train_func(model, loader_train, optimizer, scaler=None):\n",
        "    model.train()\n",
        "    train_loss = []\n",
        "    bar = tqdm(loader_train)\n",
        "    for images, targets in bar:\n",
        "        optimizer.zero_grad()\n",
        "        images = images.cuda()\n",
        "        targets = targets.cuda()\n",
        "        \n",
        "        do_mixup = False\n",
        "        if random.random() < p_mixup:\n",
        "            do_mixup = True\n",
        "            images, targets, targets_mix, lam = mixup(images, targets)\n",
        "\n",
        "        with amp.autocast():\n",
        "            logits = model(images)\n",
        "            loss = criterion(logits, targets)\n",
        "            if do_mixup:\n",
        "                loss11 = criterion(logits, targets_mix)\n",
        "                loss = loss * lam  + loss11 * (1 - lam)\n",
        "        train_loss.append(loss.item())\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        bar.set_description(f'smth:{np.mean(train_loss[-30:]):.4f}')\n",
        "\n",
        "    return np.mean(train_loss)\n",
        "\n",
        "\n",
        "def valid_func(model, loader_valid):\n",
        "    model.eval()\n",
        "    valid_loss = []\n",
        "    gts = []\n",
        "    outputs = []\n",
        "    bar = tqdm(loader_valid)\n",
        "    with torch.no_grad():\n",
        "        for images, targets in bar:\n",
        "            images = images.cuda()\n",
        "            targets = targets.cuda()\n",
        "\n",
        "            logits = model(images)\n",
        "            loss = criterion(logits, targets)\n",
        "            \n",
        "            gts.append(targets.cpu())\n",
        "            outputs.append(logits.cpu())\n",
        "            valid_loss.append(loss.item())\n",
        "            \n",
        "            bar.set_description(f'smth:{np.mean(valid_loss[-30:]):.4f}')\n",
        "\n",
        "    outputs = torch.cat(outputs)\n",
        "    gts = torch.cat(gts)\n",
        "    valid_loss = criterion(outputs, gts).item()\n",
        "\n",
        "    return valid_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "JSM6dqPSevJe",
        "outputId": "5c1b6db1-6444-4d80-ae53-af1f69615d7e"
      },
      "outputs": [],
      "source": [
        "rcParams['figure.figsize'] = 20, 2\n",
        "optimizer = optim.AdamW(m.parameters(), lr=init_lr)\n",
        "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs, eta_min=eta_min)\n",
        "\n",
        "lrs = []\n",
        "for epoch in range(1, n_epochs+1):\n",
        "    scheduler_cosine.step(epoch-1)\n",
        "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
        "plt.plot(range(len(lrs)), lrs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "422KePQje4uc"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UR3sD8AEexjX"
      },
      "outputs": [],
      "source": [
        "def run(fold):\n",
        "\n",
        "    log_file = os.path.join(log_dir, f'{kernel_type}.txt')\n",
        "    model_file = os.path.join(model_dir, f'{kernel_type}_fold{fold}_best.pth')\n",
        "\n",
        "    train_ = df[df['fold'] != fold].reset_index(drop=True)\n",
        "    valid_ = df[df['fold'] == fold].reset_index(drop=True)\n",
        "    dataset_train = CLSDataset(train_, 'train', transform=transforms_train)\n",
        "    dataset_valid = CLSDataset(valid_, 'valid', transform=transforms_valid)\n",
        "    loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
        "    loader_valid = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "    model = TimmModel(backbone, pretrained=True)\n",
        "    model = model.to(device)\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=init_lr)\n",
        "    scaler = torch.cuda.amp.GradScaler() if use_amp else None\n",
        "\n",
        "    metric_best = np.inf\n",
        "    loss_min = np.inf\n",
        "\n",
        "    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, n_epochs, eta_min=eta_min)\n",
        "\n",
        "    print(len(dataset_train), len(dataset_valid))\n",
        "\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        scheduler_cosine.step(epoch-1)\n",
        "\n",
        "        print(time.ctime(), 'Epoch:', epoch)\n",
        "\n",
        "        train_loss = train_func(model, loader_train, optimizer, scaler)\n",
        "        valid_loss = valid_func(model, loader_valid)\n",
        "        metric = valid_loss\n",
        "\n",
        "        content = time.ctime() + ' ' + f'Fold {fold}, Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {train_loss:.5f}, valid loss: {valid_loss:.5f}, metric: {(metric):.6f}.'\n",
        "        print(content)\n",
        "        with open(log_file, 'a') as appender:\n",
        "            appender.write(content + '\\n')\n",
        "\n",
        "        if metric < metric_best:\n",
        "            print(f'metric_best ({metric_best:.6f} --> {metric:.6f}). Saving model ...')\n",
        "#             if not DEBUG:\n",
        "            torch.save(model.state_dict(), model_file)\n",
        "            metric_best = metric\n",
        "\n",
        "        # Save Last\n",
        "        if not DEBUG:\n",
        "            torch.save(\n",
        "                {\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'scaler_state_dict': scaler.state_dict() if scaler else None,\n",
        "                    'score_best': metric_best,\n",
        "                },\n",
        "                model_file.replace('_best', '_last')\n",
        "            )\n",
        "\n",
        "    del model\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "O36dmARre4Km",
        "outputId": "357cd4dc-e074-4f06-dd64-44ca9acd09fe"
      },
      "outputs": [],
      "source": [
        "run(0)\n",
        "# run(1)\n",
        "# run(2)\n",
        "# run(3)\n",
        "# run(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbvkCVPFe9Cl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
